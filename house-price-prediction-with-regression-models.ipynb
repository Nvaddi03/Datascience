{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5407,"databundleVersionId":868283,"sourceType":"competition"}],"dockerImageVersionId":30673,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Load the dataset","metadata":{}},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:33:17.330171Z","iopub.execute_input":"2024-03-30T23:33:17.330551Z","iopub.status.idle":"2024-03-30T23:33:17.337353Z","shell.execute_reply.started":"2024-03-30T23:33:17.330523Z","shell.execute_reply":"2024-03-30T23:33:17.336242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Comment this if the data visualisations doesn't work on your side\n%matplotlib inline\n\ntrain_file_path = '/kaggle/input/house-prices-advanced-regression-techniques/train.csv'\ntest_file_path = '/kaggle/input/house-prices-advanced-regression-techniques/test.csv'\n\ntrain_df = pd.read_csv(train_file_path)\nforecast_df = pd.read_csv(test_file_path)\ntrain_df.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:33:17.520592Z","iopub.execute_input":"2024-03-30T23:33:17.520993Z","iopub.status.idle":"2024-03-30T23:33:20.121881Z","shell.execute_reply.started":"2024-03-30T23:33:17.520961Z","shell.execute_reply":"2024-03-30T23:33:20.120970Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## House Price Distribution\nNow, let's get statistical information about the numeric and non-numeric columns in our dataset.","metadata":{}},{"cell_type":"code","source":"train_df.describe(include = [np.number])","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:33:20.123425Z","iopub.execute_input":"2024-03-30T23:33:20.123904Z","iopub.status.idle":"2024-03-30T23:33:20.213930Z","shell.execute_reply.started":"2024-03-30T23:33:20.123876Z","shell.execute_reply":"2024-03-30T23:33:20.212850Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"isnull_features = train_df.isna().sum().sort_values(ascending = False)\nisnull_features[isnull_features >0]","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:33:20.215111Z","iopub.execute_input":"2024-03-30T23:33:20.215429Z","iopub.status.idle":"2024-03-30T23:33:20.227789Z","shell.execute_reply.started":"2024-03-30T23:33:20.215403Z","shell.execute_reply":"2024-03-30T23:33:20.226673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The highest percentage of data is missing on Pool QC. After doing further analysis with the train data set, \nPool area and pool QC both are dependent each other. Pool QS is null when pool area is 0.","metadata":{}},{"cell_type":"markdown","source":"### Handling Outlier\n\nOutlier is an observation in a given dataset that lies far from the rest of the observations. In statistics, we have three measures of central tendency namely Mean, Median, and Mode. Based on statistics, lot area and GrlivArea have high cost of mean.  ","metadata":{}},{"cell_type":"code","source":"train_df.describe(include = [np.number]).transpose().sort_values(by= 'mean', ascending = False)","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:33:20.230265Z","iopub.execute_input":"2024-03-30T23:33:20.230567Z","iopub.status.idle":"2024-03-30T23:33:20.322077Z","shell.execute_reply.started":"2024-03-30T23:33:20.230543Z","shell.execute_reply":"2024-03-30T23:33:20.321186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_df['TotalBsmtSF'].sort_values(ascending = False).head(5))\nprint(train_df['1stFlrSF'].sort_values(ascending = False).head(5))\nprint(train_df['GrLivArea'].sort_values(ascending = False).head(5))\nprint(train_df['LotArea'].sort_values(ascending = False).head(5))","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:33:20.323341Z","iopub.execute_input":"2024-03-30T23:33:20.323923Z","iopub.status.idle":"2024-03-30T23:33:20.334332Z","shell.execute_reply.started":"2024-03-30T23:33:20.323895Z","shell.execute_reply":"2024-03-30T23:33:20.333197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plot the scatter plot to visualize the outlier and delete outlier from data set.","metadata":{}},{"cell_type":"code","source":"# clear outliers\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nfig, axes = plt.subplots(ncols=4, nrows=2, figsize=(20,3))\naxes = np.ravel(axes)\n#High mean cols names more than 1000 excepy years\ncol_names=['TotalBsmtSF','1stFlrSF', 'GrLivArea','LotArea']\nfor i, c in zip(range(5), col_names):\n    train_df.plot.scatter(ax=axes[i], x=c, y='SalePrice', sharey=True, colorbar=False, c='r')\nprint(train_df.shape)\n\ntrain_df = train_df[train_df['TotalBsmtSF'] < 3000]\ntrain_df = train_df[train_df['1stFlrSF'] < 2500]\ntrain_df = train_df[train_df['GrLivArea'] < 4000]\ntrain_df = train_df[train_df['LotArea'] < 100000]\nprint(train_df.shape)\n\nfor i, c in zip(range(4,9), col_names):\n    train_df.plot.scatter(ax=axes[i], x=c, y='SalePrice', sharey=True, colorbar=False, c='b')","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:33:20.335525Z","iopub.execute_input":"2024-03-30T23:33:20.335875Z","iopub.status.idle":"2024-03-30T23:33:21.871647Z","shell.execute_reply.started":"2024-03-30T23:33:20.335848Z","shell.execute_reply":"2024-03-30T23:33:21.870475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Correlation\nWe want to see how the dataset variables are correlated with each other and how predictor variables are correlated with the target variable. Spearmanâ€™s Rank Correlation is a statistical measure of the strength and direction of the monotonic relationship between two continuous variables","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom scipy.stats import spearmanr\nimport matplotlib.pyplot as plt\n\n\nanscombe_data = train_df.drop('SalePrice', axis=1)\n# Selecting four sets of 11 data points\nsubset_data = anscombe_data[anscombe_data.columns]\n\nscore = []\nfor col in subset_data:\n    corr, pval = spearmanr(anscombe_data[col], train_df['SalePrice'])\n    score.append([col, corr, pval])\n\nspearmanr_score =  pd.DataFrame(score, columns=['Field','correlation', 'p-value'])\nspearmanr_score = spearmanr_score[spearmanr_score['correlation'] > 0.5].sort_values(by = 'correlation', \n                                                                                        ascending = False)\n#spearmanr_score = spearmanr_score.sort_values(by = 'p-value',ascending = False)\nspearmanr_score.reset_index(drop=True, inplace=True)\nspearmanr_score","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:33:21.873589Z","iopub.execute_input":"2024-03-30T23:33:21.874604Z","iopub.status.idle":"2024-03-30T23:33:22.181281Z","shell.execute_reply.started":"2024-03-30T23:33:21.874565Z","shell.execute_reply":"2024-03-30T23:33:22.180016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = spearmanr_score['Field'].tolist()\ng = sns.PairGrid(train_df, y_vars=[\"SalePrice\"], x_vars=x);\ng.map(plt.scatter, color=\"orange\", edgecolors=\"#000000\", linewidths=0.5);\n#taking a copy of data set before start cleaning data.\ntrain = train_df\ntest = forecast_df","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:33:22.182791Z","iopub.execute_input":"2024-03-30T23:33:22.183928Z","iopub.status.idle":"2024-03-30T23:33:24.131280Z","shell.execute_reply.started":"2024-03-30T23:33:22.183886Z","shell.execute_reply":"2024-03-30T23:33:24.130194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature Engineering","metadata":{}},{"cell_type":"code","source":"from datetime import datetime\n\ncurrent_year = datetime.now().year\ntrain['ageofhouse'] = current_year - train['YearBuilt']\ntrain['ageofgrg'] = current_year - train['GarageYrBlt']\ntrain['nooffullbath'] = train['BsmtFullBath']+ train['FullBath']\ntrain['nohalfbath'] = train['BsmtHalfBath']+ train['HalfBath']\n\ntest['ageofhouse'] = current_year - test['YearBuilt']\ntest['ageofgrg'] = current_year - test['GarageYrBlt']\ntest['nooffullbath'] = test['BsmtFullBath']+ train['FullBath']\ntest['nohalfbath'] = test['BsmtHalfBath']+ train['HalfBath']\n\n\ntrain.drop(['YearBuilt','GarageYrBlt','BsmtFullBath','FullBath','BsmtHalfBath','HalfBath'], inplace = True, axis=1)\ntest.drop(['YearBuilt', 'GarageYrBlt','BsmtFullBath','FullBath','BsmtHalfBath','HalfBath'], inplace = True, axis=1)\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:33:24.132555Z","iopub.execute_input":"2024-03-30T23:33:24.132854Z","iopub.status.idle":"2024-03-30T23:33:24.171676Z","shell.execute_reply.started":"2024-03-30T23:33:24.132829Z","shell.execute_reply":"2024-03-30T23:33:24.170619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data pre-process","metadata":{}},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import Ridge,Lasso,ElasticNet\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\n# Separate features and target variable\nX = train.drop(columns=[\"SalePrice\"])\ny = train[\"SalePrice\"] \n\n\n# Define categorical and numerical features\ncategorical_features = X.select_dtypes(include=['object']).columns.tolist()\nnumerical_features =X.select_dtypes(exclude=['object']).columns.tolist()\n\n# Define preprocesing steps\nnumeric_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='median')),\n    ('scaler', StandardScaler())])\n\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))])","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:33:24.175296Z","iopub.execute_input":"2024-03-30T23:33:24.175619Z","iopub.status.idle":"2024-03-30T23:33:24.603849Z","shell.execute_reply.started":"2024-03-30T23:33:24.175594Z","shell.execute_reply":"2024-03-30T23:33:24.602890Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, numerical_features),\n        ('cat', categorical_transformer, categorical_features)])","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:33:24.605224Z","iopub.execute_input":"2024-03-30T23:33:24.605515Z","iopub.status.idle":"2024-03-30T23:33:24.609295Z","shell.execute_reply.started":"2024-03-30T23:33:24.605492Z","shell.execute_reply":"2024-03-30T23:33:24.608481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model validation before Tuning.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom sklearn.exceptions import ConvergenceWarning\nimport warnings\n\nwarnings.filterwarnings('ignore')\nwarnings.filterwarnings('ignore', category=ConvergenceWarning)\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:33:24.610637Z","iopub.execute_input":"2024-03-30T23:33:24.610951Z","iopub.status.idle":"2024-03-30T23:33:36.855248Z","shell.execute_reply.started":"2024-03-30T23:33:24.610925Z","shell.execute_reply":"2024-03-30T23:33:36.854254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ML_models(model, X_train, X_test, y_train, y_test, preprocessor):\n    \n    regr_trans = Pipeline(steps=[('preprocessor', preprocessor),\n                                 ('model', model)])\n    regr_trans.fit(X_train, y_train)\n    yhat = regr_trans.predict(X_test)\n    algoname= model.__class__.__name__\n\n    scores = cross_val_score(regr_trans, X, y, cv=5)\n    mean_accuracy = scores.mean()\n    \n    return (algoname, round(r2_score(y_test, yhat),3), np.sqrt(mean_squared_error(y_test, yhat)),\n            mean_accuracy )","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:33:36.856407Z","iopub.execute_input":"2024-03-30T23:33:36.856970Z","iopub.status.idle":"2024-03-30T23:33:36.866122Z","shell.execute_reply.started":"2024-03-30T23:33:36.856942Z","shell.execute_reply":"2024-03-30T23:33:36.865070Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\nimport lightgbm as lgbm\nimport xgboost as xg\nfrom sklearn import linear_model\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.compose import TransformedTargetRegressor\nfrom sklearn.metrics import mean_absolute_error, r2_score, mean_squared_log_error\nfrom sklearn.linear_model import Ridge\nfrom sklearn import svm\nfrom catboost import CatBoostRegressor\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder, QuantileTransformer\n#from sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.neural_network import MLPRegressor\n\n#params = {'model__verbose': -1 }\n\nalgo=[GradientBoostingRegressor(), \n      lgbm.LGBMRegressor(), \n      xg.XGBRFRegressor(),\n      xg.XGBRegressor(),\n      linear_model.LinearRegression(), \n      RandomForestRegressor(),\n      DecisionTreeRegressor(), \n      linear_model.Lasso(),\n      Ridge(),\n      svm.SVR(),\n      CatBoostRegressor(verbose=False),\n      linear_model.ElasticNet(alpha=1.0, l1_ratio=0.5)\n      ]\n\nscore=[]\n\nfor model in algo:\n    score.append(ML_models(model, X_train, X_test, y_train, y_test, preprocessor))","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:33:36.870489Z","iopub.execute_input":"2024-03-30T23:33:36.872483Z","iopub.status.idle":"2024-03-30T23:35:44.283794Z","shell.execute_reply.started":"2024-03-30T23:33:36.872446Z","shell.execute_reply":"2024-03-30T23:35:44.282497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(pd.DataFrame(score, columns=['Model', 'R2-Score', 'RMSE', 'cross_val_score' ]).\n      sort_values(by='cross_val_score', ascending = False))","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:35:44.285232Z","iopub.execute_input":"2024-03-30T23:35:44.285590Z","iopub.status.idle":"2024-03-30T23:35:44.296681Z","shell.execute_reply.started":"2024-03-30T23:35:44.285553Z","shell.execute_reply":"2024-03-30T23:35:44.295603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The Best models are GradientBoostingRegressor, LGBMRegressor, CatBoostRegressor","metadata":{}},{"cell_type":"code","source":"def gridsearch(pipeline, parameter_space, X_train, y_train):\n    # Perform GridSearchCV\n    clf = GridSearchCV(pipeline, \n                       parameter_space, \n                       cv=5, \n                       scoring='neg_root_mean_squared_error' \n                       #,verbose=2\n                      )\n    clf.fit(X_train, y_train)\n    return clf.best_params_","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:35:44.297865Z","iopub.execute_input":"2024-03-30T23:35:44.298205Z","iopub.status.idle":"2024-03-30T23:35:44.308552Z","shell.execute_reply.started":"2024-03-30T23:35:44.298171Z","shell.execute_reply":"2024-03-30T23:35:44.307460Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### CatBoostRegressor","metadata":{}},{"cell_type":"code","source":"model = CatBoostRegressor(verbose=False)\npipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                           ('regressor', model)])\n\n\nparameter_space = {'regressor__depth' : [6,8,10],\n                  'regressor__learning_rate' : [0.01, 0.05, 0.1],\n                  'regressor__iterations'    : [30, 50, 100]\n              }\n\nclf = GridSearchCV(estimator=pipeline, \n                   param_grid = parameter_space, \n                   cv = 5, \n                   n_jobs=-1, \n                   scoring='neg_root_mean_squared_error')\nclf.fit(X, y)\nprint('Best parms: ', clf.best_params_)\n#print('Best Estimators: ', clf.best_estimator_)\n\ny_hat = clf.best_estimator_.predict(X)\n\nprint('RMSE: %.2f' % np.sqrt(mean_squared_error(y, y_hat)))\nprint('R2 Score: %.2f' % r2_score(y, y_hat),3) ","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:35:44.309914Z","iopub.execute_input":"2024-03-30T23:35:44.311102Z","iopub.status.idle":"2024-03-30T23:38:03.859475Z","shell.execute_reply.started":"2024-03-30T23:35:44.311058Z","shell.execute_reply":"2024-03-30T23:38:03.858378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### GradientBoostingRegressor","metadata":{}},{"cell_type":"code","source":"#GradientBoostingRegressor\nmodel = GradientBoostingRegressor()\npipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                           ('regressor', model)])\n\nparameter_space = {\n                    \"regressor__learning_rate\": [0.0001, 0.001, 0.01, 0.1, 1.0],\n                    \"regressor__n_estimators\": [5, 10, 50],\n                    \"regressor__subsample\": [0.5, 0.7, 1.0],\n                    \"regressor__max_depth\": [3, 5]\n                }\n\nclf = GridSearchCV(estimator=pipeline, \n                   param_grid = parameter_space, \n                   cv = 5, \n                   n_jobs=-1, \n                   scoring='neg_root_mean_squared_error')\nclf.fit(X, y)\nprint('Best parms: ', clf.best_params_)\n#print('Best Estimators: ', clf.best_estimator_)\n\ny_hat = clf.best_estimator_.predict(X)\n\nprint('RMSE: %.2f' % np.sqrt(mean_squared_error(y, y_hat)))\nprint('R2 Score: %.2f' % r2_score(y, y_hat),3) ","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:38:03.860610Z","iopub.execute_input":"2024-03-30T23:38:03.860891Z","iopub.status.idle":"2024-03-30T23:41:18.235759Z","shell.execute_reply.started":"2024-03-30T23:38:03.860869Z","shell.execute_reply":"2024-03-30T23:41:18.234426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### LGBRegressor","metadata":{}},{"cell_type":"code","source":"#LGBRegressor \nmodel = lgbm.LGBMRegressor(verbosity=-1)\npipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                           ('regressor', model)])\n\nparameter_space = {\n                    'regressor__num_leaves': [7, 14, 21, 28, 31, 50],\n                    'regressor__learning_rate': [0.1, 0.03, 0.003],\n                    'regressor__max_depth': [-1, 3, 5],\n                    'regressor__n_estimators': [50, 100, 200, 500],\n                }\n\nclf = GridSearchCV(estimator=pipeline, \n                   param_grid = parameter_space, \n                   cv = 5, \n                   n_jobs=-1, \n                   scoring='neg_root_mean_squared_error')\nclf.fit(X, y)\nprint('Best parms: ', clf.best_params_)\n#print('Best Estimators: ', clf.best_estimator_)\n\ny_hat = clf.best_estimator_.predict(X)\n\nprint('RMSE: %.2f' % np.sqrt(mean_squared_error(y, y_hat)))\nprint('R2 Score: %.2f' % r2_score(y, y_hat),3) \n","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:41:18.237283Z","iopub.execute_input":"2024-03-30T23:41:18.237875Z","iopub.status.idle":"2024-03-30T23:47:54.888752Z","shell.execute_reply.started":"2024-03-30T23:41:18.237847Z","shell.execute_reply":"2024-03-30T23:47:54.887784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### RidgeRegressor","metadata":{}},{"cell_type":"code","source":"#Ridge\npipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                           ('regressor', Ridge(random_state=3))])\nparameter_space = {\n    \"regressor__alpha\": [1, 10, 100],\n    \"regressor__fit_intercept\": [True, False],\n    \"regressor__solver\": ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],\n}\n\nclf = GridSearchCV(pipeline, parameter_space, cv=5, scoring='neg_root_mean_squared_error')\nclf.fit(X, y)\n\ny_hat = clf.best_estimator_.predict(X)\n\nprint('Best parms: ', clf.best_params_)\nprint('RMSE: %.2f' % np.sqrt(mean_squared_error(y, y_hat)))\nprint('R2 Score: %.2f' % r2_score(y, y_hat),3) ","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:47:54.890005Z","iopub.execute_input":"2024-03-30T23:47:54.890355Z","iopub.status.idle":"2024-03-30T23:48:33.308082Z","shell.execute_reply.started":"2024-03-30T23:47:54.890328Z","shell.execute_reply":"2024-03-30T23:48:33.307295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### LassoRegressor","metadata":{}},{"cell_type":"code","source":"#Lasso\npipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                           ('regressor', linear_model.Lasso())])\n\nparameter_space = {\n                    \"regressor__alpha\": [0.1, 1, 10, 100],\n                    \"regressor__fit_intercept\": [True, False],\n                    \"regressor__precompute\": [True, False],\n                    \"regressor__copy_X\": [True, False],\n                    \"regressor__selection\": ['cyclic']\n                   }\n\n\nclf = GridSearchCV(pipeline, parameter_space, cv=5, scoring='neg_root_mean_squared_error')\nclf.fit(X, y)\ny_hat = clf.best_estimator_.predict(X)\n\nprint('Best Parm: ', clf.best_params_)\nprint('RMSE: %.2f' % np.sqrt(mean_squared_error(y, y_hat)))\nprint('R2 Score: %.2f' % r2_score(y, y_hat),3) ","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:48:33.309281Z","iopub.execute_input":"2024-03-30T23:48:33.309751Z","iopub.status.idle":"2024-03-30T23:51:07.685312Z","shell.execute_reply.started":"2024-03-30T23:48:33.309725Z","shell.execute_reply":"2024-03-30T23:51:07.683999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### RandomForestRegressor","metadata":{}},{"cell_type":"code","source":"#Randomeforest\n\n#from sklearn.metrics import mean_squared_error\n#from sklearn.model_selection import GridSearchCV\n# Create a pipeline with preprocessing and RandomForestRegressor model\npipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                           ('regressor', RandomForestRegressor(random_state=42))])\n\n# Define parameter grid for GridSearchCV\nparameter_space = {\n    'regressor__n_estimators': [100, 200, 300],\n    'regressor__max_depth': [None, 10, 20, 30]\n}\n\nclf = GridSearchCV(pipeline, parameter_space, cv=5, scoring='neg_root_mean_squared_error')\nclf.fit(X, y)\n\n# Get the best model from grid search\nbest_model = clf.best_estimator_\n\ny_hat = clf.best_estimator_.predict(X)\nprint('Best Parameter:', clf.best_params_)\nprint('RMSE: %.2f' % np.sqrt(mean_squared_error(y, y_hat)))\nprint('R2 Score: %.2f' % r2_score(y, y_hat),3) \n","metadata":{"execution":{"iopub.status.busy":"2024-03-30T23:51:07.687042Z","iopub.execute_input":"2024-03-30T23:51:07.687727Z","iopub.status.idle":"2024-03-31T00:11:51.950372Z","shell.execute_reply.started":"2024-03-30T23:51:07.687688Z","shell.execute_reply":"2024-03-31T00:11:51.949186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Based on RMSE and R2-score, the Best model is - RandomForestRegressor","metadata":{}},{"cell_type":"markdown","source":"#### Model Prediction on test data & Submission","metadata":{}},{"cell_type":"code","source":"# Evaluate the models on the validation data\ny_test_pred = best_model.predict(test)\n\n#Create a DataFrame with the predicted values\npredictions_df = pd.DataFrame({'Id': test['Id'], 'SalePrice':y_test_pred})\n\n# Print or display the DataFrame\nprint(\"Test dataset with predicted sale prices:\")\nprint(predictions_df)\npredictions_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T00:25:35.926485Z","iopub.execute_input":"2024-03-31T00:25:35.926881Z","iopub.status.idle":"2024-03-31T00:25:36.162778Z","shell.execute_reply.started":"2024-03-31T00:25:35.926844Z","shell.execute_reply":"2024-03-31T00:25:36.161437Z"},"trusted":true},"execution_count":null,"outputs":[]}]}