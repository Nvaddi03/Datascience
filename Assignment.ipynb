{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e14d454-2b39-4990-b4b3-bfbe8917b71c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/sklearn/utils/validation.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  LARGE_SPARSE_SUPPORTED = LooseVersion(scipy_version) >= '0.14.0'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fed1a12-3364-48ed-8fca-6300a04827fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "0            1040.0           676.0   28     79.99  \n",
       "1            1055.0           676.0   28     61.89  \n",
       "2             932.0           594.0  270     40.27  \n",
       "3             932.0           594.0  365     41.05  \n",
       "4             978.4           825.5  360     44.30  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'http://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0101EN/labs/data/concrete_data.csv'\n",
    "concreat_data = pd.read_csv(url)\n",
    "concreat_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99dc5435-5c87-45c0-8d98-0f78e74ece2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_cols = concreat_data.columns\n",
    "X = concreat_data[data_cols[data_cols !='Strength']]\n",
    "y = concreat_data['Strength']\n",
    "n_cols = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aeced05f-28cd-47b9-9e78-d4c708654e3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def regression_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc4c33b1-d903-47d0-a024-0feab08290f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 504 samples, validate on 217 samples\n",
      "Epoch 1/50\n",
      " - 0s - loss: 25702.8188 - val_loss: 16144.2608\n",
      "Epoch 2/50\n",
      " - 0s - loss: 8827.2597 - val_loss: 5052.3539\n",
      "Epoch 3/50\n",
      " - 0s - loss: 3331.1402 - val_loss: 2613.2218\n",
      "Epoch 4/50\n",
      " - 0s - loss: 2703.3831 - val_loss: 2396.6737\n",
      "Epoch 5/50\n",
      " - 0s - loss: 2583.3897 - val_loss: 2282.4061\n",
      "Epoch 6/50\n",
      " - 0s - loss: 2407.5428 - val_loss: 2194.3470\n",
      "Epoch 7/50\n",
      " - 0s - loss: 2274.0975 - val_loss: 2088.0788\n",
      "Epoch 8/50\n",
      " - 0s - loss: 2147.1279 - val_loss: 1942.6729\n",
      "Epoch 9/50\n",
      " - 0s - loss: 2012.6451 - val_loss: 1829.7034\n",
      "Epoch 10/50\n",
      " - 0s - loss: 1884.2226 - val_loss: 1710.7977\n",
      "Epoch 11/50\n",
      " - 0s - loss: 1763.0065 - val_loss: 1596.6803\n",
      "Epoch 12/50\n",
      " - 0s - loss: 1651.2553 - val_loss: 1479.8899\n",
      "Epoch 13/50\n",
      " - 0s - loss: 1534.0826 - val_loss: 1399.2936\n",
      "Epoch 14/50\n",
      " - 0s - loss: 1423.1796 - val_loss: 1277.9016\n",
      "Epoch 15/50\n",
      " - 0s - loss: 1314.9332 - val_loss: 1199.2295\n",
      "Epoch 16/50\n",
      " - 0s - loss: 1217.9706 - val_loss: 1113.9149\n",
      "Epoch 17/50\n",
      " - 0s - loss: 1125.8154 - val_loss: 1028.6281\n",
      "Epoch 18/50\n",
      " - 0s - loss: 1036.8440 - val_loss: 944.4582\n",
      "Epoch 19/50\n",
      " - 0s - loss: 958.5764 - val_loss: 876.8632\n",
      "Epoch 20/50\n",
      " - 0s - loss: 884.4312 - val_loss: 830.0548\n",
      "Epoch 21/50\n",
      " - 0s - loss: 811.9228 - val_loss: 748.8426\n",
      "Epoch 22/50\n",
      " - 0s - loss: 746.6427 - val_loss: 693.8898\n",
      "Epoch 23/50\n",
      " - 0s - loss: 684.2189 - val_loss: 648.6586\n",
      "Epoch 24/50\n",
      " - 0s - loss: 629.5136 - val_loss: 598.3443\n",
      "Epoch 25/50\n",
      " - 0s - loss: 579.2950 - val_loss: 552.9760\n",
      "Epoch 26/50\n",
      " - 0s - loss: 531.6659 - val_loss: 515.6452\n",
      "Epoch 27/50\n",
      " - 0s - loss: 489.8354 - val_loss: 480.8328\n",
      "Epoch 28/50\n",
      " - 0s - loss: 452.4481 - val_loss: 447.8008\n",
      "Epoch 29/50\n",
      " - 0s - loss: 418.0339 - val_loss: 418.7574\n",
      "Epoch 30/50\n",
      " - 0s - loss: 386.7031 - val_loss: 393.4998\n",
      "Epoch 31/50\n",
      " - 0s - loss: 359.8180 - val_loss: 371.3511\n",
      "Epoch 32/50\n",
      " - 0s - loss: 336.0903 - val_loss: 351.6375\n",
      "Epoch 33/50\n",
      " - 0s - loss: 312.8972 - val_loss: 332.9557\n",
      "Epoch 34/50\n",
      " - 0s - loss: 294.3836 - val_loss: 317.8899\n",
      "Epoch 35/50\n",
      " - 0s - loss: 278.0330 - val_loss: 303.1365\n",
      "Epoch 36/50\n",
      " - 0s - loss: 262.3532 - val_loss: 290.6073\n",
      "Epoch 37/50\n",
      " - 0s - loss: 248.4126 - val_loss: 279.5253\n",
      "Epoch 38/50\n",
      " - 0s - loss: 235.6876 - val_loss: 270.0241\n",
      "Epoch 39/50\n",
      " - 0s - loss: 225.3719 - val_loss: 261.3621\n",
      "Epoch 40/50\n",
      " - 0s - loss: 217.0630 - val_loss: 253.5882\n",
      "Epoch 41/50\n",
      " - 0s - loss: 208.3996 - val_loss: 246.6181\n",
      "Epoch 42/50\n",
      " - 0s - loss: 201.3236 - val_loss: 240.8569\n",
      "Epoch 43/50\n",
      " - 0s - loss: 194.6013 - val_loss: 234.6274\n",
      "Epoch 44/50\n",
      " - 0s - loss: 189.5062 - val_loss: 231.6862\n",
      "Epoch 45/50\n",
      " - 0s - loss: 183.8053 - val_loss: 225.0211\n",
      "Epoch 46/50\n",
      " - 0s - loss: 179.2755 - val_loss: 221.8270\n",
      "Epoch 47/50\n",
      " - 0s - loss: 175.0019 - val_loss: 216.4976\n",
      "Epoch 48/50\n",
      " - 0s - loss: 172.2413 - val_loss: 213.3977\n",
      "Epoch 49/50\n",
      " - 0s - loss: 168.0906 - val_loss: 210.0415\n",
      "Epoch 50/50\n",
      " - 0s - loss: 164.7925 - val_loss: 208.2895\n",
      "309/309 [==============================] - 0s 45us/step\n",
      "mean_squared_error:-  173.02384742710677\n"
     ]
    }
   ],
   "source": [
    "#2. Train the model on the training data using 50 epochs.\n",
    "#3. Evaluate the model on the test data and compute the mean squared error between the predicted concrete strength and the actual concrete strength. \n",
    "#You can use the mean_squared_error function from Scikit-learn.\n",
    "model = regression_model()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "model.fit(X_train,y_train, verbose=2, epochs=50,validation_split=0.3 )\n",
    "scores = model.evaluate(X_test,y_test)\n",
    "y_hat = model.predict(X_test)\n",
    "\n",
    "print('mean_squared_error:- ', mean_squared_error(y_test,y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1be7506d-f0b0-4807-887e-1c4b571e331c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#4. Repeat steps 1 - 3, 50 times, i.e., create a list of 50 mean squared errors.\n",
    "def get_mse(model, predict, epochs):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(predict, y, test_size=0.3)\n",
    "    model.fit(X_train, y_train, verbose=0, epochs= epochs, validation_split=0.3)\n",
    "    y_hat = model.predict(X_test)\n",
    "    return  mean_squared_error(y_test, y_hat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48f98568-5382-4df8-90ff-2219de86f9e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iteration - ', 1, 'mean_squared_error - ', 860.3976664643183)\n",
      "('Iteration - ', 2, 'mean_squared_error - ', 532.5688120262531)\n",
      "('Iteration - ', 3, 'mean_squared_error - ', 383.2855905092114)\n",
      "('Iteration - ', 4, 'mean_squared_error - ', 223.88553231164647)\n",
      "('Iteration - ', 5, 'mean_squared_error - ', 189.65729036535703)\n",
      "('Iteration - ', 6, 'mean_squared_error - ', 127.9811278818352)\n",
      "('Iteration - ', 7, 'mean_squared_error - ', 119.10612186244207)\n",
      "('Iteration - ', 8, 'mean_squared_error - ', 118.0448483714883)\n",
      "('Iteration - ', 9, 'mean_squared_error - ', 111.62224202022587)\n",
      "('Iteration - ', 10, 'mean_squared_error - ', 124.6485947806295)\n",
      "('Iteration - ', 11, 'mean_squared_error - ', 96.44069145786362)\n",
      "('Iteration - ', 12, 'mean_squared_error - ', 86.55219444759013)\n",
      "('Iteration - ', 13, 'mean_squared_error - ', 81.35272511194424)\n",
      "('Iteration - ', 14, 'mean_squared_error - ', 64.10910967568728)\n",
      "('Iteration - ', 15, 'mean_squared_error - ', 58.88119679369688)\n",
      "('Iteration - ', 16, 'mean_squared_error - ', 61.153462104645)\n",
      "('Iteration - ', 17, 'mean_squared_error - ', 54.05237483995363)\n",
      "('Iteration - ', 18, 'mean_squared_error - ', 47.90122911795827)\n",
      "('Iteration - ', 19, 'mean_squared_error - ', 46.498041190339315)\n",
      "('Iteration - ', 20, 'mean_squared_error - ', 47.83656507539006)\n",
      "('Iteration - ', 21, 'mean_squared_error - ', 52.842388811042916)\n",
      "('Iteration - ', 22, 'mean_squared_error - ', 49.15273347578278)\n",
      "('Iteration - ', 23, 'mean_squared_error - ', 44.00082768110519)\n",
      "('Iteration - ', 24, 'mean_squared_error - ', 45.65626115768917)\n",
      "('Iteration - ', 25, 'mean_squared_error - ', 50.5134244718596)\n",
      "('Iteration - ', 26, 'mean_squared_error - ', 58.01469019838742)\n",
      "('Iteration - ', 27, 'mean_squared_error - ', 44.44202832469249)\n",
      "('Iteration - ', 28, 'mean_squared_error - ', 48.41948438807239)\n",
      "('Iteration - ', 29, 'mean_squared_error - ', 49.0400723077354)\n",
      "('Iteration - ', 30, 'mean_squared_error - ', 52.29798942651755)\n",
      "('Iteration - ', 31, 'mean_squared_error - ', 51.814610765000104)\n",
      "('Iteration - ', 32, 'mean_squared_error - ', 44.20773605950974)\n",
      "('Iteration - ', 33, 'mean_squared_error - ', 43.28467546237769)\n",
      "('Iteration - ', 34, 'mean_squared_error - ', 49.2751451985784)\n",
      "('Iteration - ', 35, 'mean_squared_error - ', 42.204087535243126)\n",
      "('Iteration - ', 36, 'mean_squared_error - ', 46.914132060638096)\n",
      "('Iteration - ', 37, 'mean_squared_error - ', 52.3925292856829)\n",
      "('Iteration - ', 38, 'mean_squared_error - ', 40.663654289460354)\n",
      "('Iteration - ', 39, 'mean_squared_error - ', 44.09822453316676)\n",
      "('Iteration - ', 40, 'mean_squared_error - ', 48.97249925096112)\n",
      "('Iteration - ', 41, 'mean_squared_error - ', 47.4953522146959)\n",
      "('Iteration - ', 42, 'mean_squared_error - ', 45.602134229192906)\n",
      "('Iteration - ', 43, 'mean_squared_error - ', 42.62253950662216)\n",
      "('Iteration - ', 44, 'mean_squared_error - ', 40.49937805115264)\n",
      "('Iteration - ', 45, 'mean_squared_error - ', 44.374842512699)\n",
      "('Iteration - ', 46, 'mean_squared_error - ', 50.29028039754169)\n",
      "('Iteration - ', 47, 'mean_squared_error - ', 49.36315933277187)\n",
      "('Iteration - ', 48, 'mean_squared_error - ', 53.32999280105381)\n",
      "('Iteration - ', 49, 'mean_squared_error - ', 47.718690018005496)\n",
      "('Iteration - ', 50, 'mean_squared_error - ', 48.27428060611683)\n"
     ]
    }
   ],
   "source": [
    "model_a = regression_model()\n",
    "lst_mse = []\n",
    "for i in range(1,51):\n",
    "    mse = get_mse(model_a, X, 50)\n",
    "    msg = ('Iteration - ', i, 'mean_squared_error - ', mse)\n",
    "    print(msg)\n",
    "    lst_mse.append(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a6ebe706-d29f-438b-96bc-fae78651e51c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 97.28\n",
      "standard deviation: 139.22\n"
     ]
    }
   ],
   "source": [
    "#Report the mean and the standard deviation of the mean squared errors.\n",
    "import numpy as np\n",
    "mse_A =np.mean(lst_mse)\n",
    "std_A = np.std((lst_mse))\n",
    "print(\"Mean: %.2f\" % np.mean(lst_mse))\n",
    "print(\"standard deviation: %.2f\" % np.std((lst_mse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f5ecec82-bbe2-4f3e-8a2a-87db7c4b049e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 504 samples, validate on 217 samples\n",
      "Epoch 1/50\n",
      " - 0s - loss: 1625.1145 - val_loss: 1707.3116\n",
      "Epoch 2/50\n",
      " - 0s - loss: 1611.6413 - val_loss: 1693.6404\n",
      "Epoch 3/50\n",
      " - 0s - loss: 1598.3234 - val_loss: 1680.6466\n",
      "Epoch 4/50\n",
      " - 0s - loss: 1585.7184 - val_loss: 1667.8310\n",
      "Epoch 5/50\n",
      " - 0s - loss: 1573.4560 - val_loss: 1655.2047\n",
      "Epoch 6/50\n",
      " - 0s - loss: 1561.3798 - val_loss: 1643.1304\n",
      "Epoch 7/50\n",
      " - 0s - loss: 1549.6409 - val_loss: 1631.5227\n",
      "Epoch 8/50\n",
      " - 0s - loss: 1538.1742 - val_loss: 1620.0665\n",
      "Epoch 9/50\n",
      " - 0s - loss: 1526.8316 - val_loss: 1608.7232\n",
      "Epoch 10/50\n",
      " - 0s - loss: 1515.4157 - val_loss: 1597.6415\n",
      "Epoch 11/50\n",
      " - 0s - loss: 1504.5222 - val_loss: 1586.1890\n",
      "Epoch 12/50\n",
      " - 0s - loss: 1493.2789 - val_loss: 1574.9778\n",
      "Epoch 13/50\n",
      " - 0s - loss: 1482.0106 - val_loss: 1563.8403\n",
      "Epoch 14/50\n",
      " - 0s - loss: 1470.9300 - val_loss: 1552.3719\n",
      "Epoch 15/50\n",
      " - 0s - loss: 1459.2667 - val_loss: 1541.0276\n",
      "Epoch 16/50\n",
      " - 0s - loss: 1447.9114 - val_loss: 1529.2103\n",
      "Epoch 17/50\n",
      " - 0s - loss: 1436.0216 - val_loss: 1517.1793\n",
      "Epoch 18/50\n",
      " - 0s - loss: 1423.9741 - val_loss: 1504.7197\n",
      "Epoch 19/50\n",
      " - 0s - loss: 1411.4695 - val_loss: 1492.1770\n",
      "Epoch 20/50\n",
      " - 0s - loss: 1398.9241 - val_loss: 1479.0617\n",
      "Epoch 21/50\n",
      " - 0s - loss: 1385.8453 - val_loss: 1465.7482\n",
      "Epoch 22/50\n",
      " - 0s - loss: 1372.4452 - val_loss: 1452.0716\n",
      "Epoch 23/50\n",
      " - 0s - loss: 1358.5414 - val_loss: 1438.1064\n",
      "Epoch 24/50\n",
      " - 0s - loss: 1344.4652 - val_loss: 1423.5829\n",
      "Epoch 25/50\n",
      " - 0s - loss: 1329.9603 - val_loss: 1408.7178\n",
      "Epoch 26/50\n",
      " - 0s - loss: 1315.1279 - val_loss: 1393.4224\n",
      "Epoch 27/50\n",
      " - 0s - loss: 1299.8568 - val_loss: 1377.9211\n",
      "Epoch 28/50\n",
      " - 0s - loss: 1284.1643 - val_loss: 1362.2135\n",
      "Epoch 29/50\n",
      " - 0s - loss: 1268.3485 - val_loss: 1345.7570\n",
      "Epoch 30/50\n",
      " - 0s - loss: 1252.1036 - val_loss: 1328.8491\n",
      "Epoch 31/50\n",
      " - 0s - loss: 1235.1943 - val_loss: 1312.1255\n",
      "Epoch 32/50\n",
      " - 0s - loss: 1218.6183 - val_loss: 1294.6862\n",
      "Epoch 33/50\n",
      " - 0s - loss: 1201.3111 - val_loss: 1277.3554\n",
      "Epoch 34/50\n",
      " - 0s - loss: 1184.1575 - val_loss: 1259.5046\n",
      "Epoch 35/50\n",
      " - 0s - loss: 1166.7119 - val_loss: 1241.5876\n",
      "Epoch 36/50\n",
      " - 0s - loss: 1148.9179 - val_loss: 1224.1465\n",
      "Epoch 37/50\n",
      " - 0s - loss: 1131.4516 - val_loss: 1206.2818\n",
      "Epoch 38/50\n",
      " - 0s - loss: 1113.7304 - val_loss: 1188.1202\n",
      "Epoch 39/50\n",
      " - 0s - loss: 1095.9889 - val_loss: 1169.5900\n",
      "Epoch 40/50\n",
      " - 0s - loss: 1077.5688 - val_loss: 1151.3847\n",
      "Epoch 41/50\n",
      " - 0s - loss: 1059.7471 - val_loss: 1132.5176\n",
      "Epoch 42/50\n",
      " - 0s - loss: 1041.5959 - val_loss: 1113.7526\n",
      "Epoch 43/50\n",
      " - 0s - loss: 1022.9521 - val_loss: 1095.5459\n",
      "Epoch 44/50\n",
      " - 0s - loss: 1004.9387 - val_loss: 1077.0554\n",
      "Epoch 45/50\n",
      " - 0s - loss: 986.6632 - val_loss: 1058.5235\n",
      "Epoch 46/50\n",
      " - 0s - loss: 968.6110 - val_loss: 1039.7468\n",
      "Epoch 47/50\n",
      " - 0s - loss: 950.4112 - val_loss: 1021.1318\n",
      "Epoch 48/50\n",
      " - 0s - loss: 932.2992 - val_loss: 1002.7886\n",
      "Epoch 49/50\n",
      " - 0s - loss: 913.9014 - val_loss: 985.0568\n",
      "Epoch 50/50\n",
      " - 0s - loss: 896.3231 - val_loss: 966.4451\n"
     ]
    }
   ],
   "source": [
    "#B. Normalize the data (5 marks) \n",
    "#Repeat Part A but use a normalized version of the data. Recall that one way to normalize the data is by subtracting \n",
    "#the mean from the individual predictors and dividing by the standard deviation.\n",
    "#How does the mean of the mean squared errors compare to that from Step A?\n",
    "predictor_norm = (X - X.mean())/X.std()\n",
    "n_cols = predictor_norm.shape[1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictor_norm, y, test_size=0.3)\n",
    "model_b = regression_model()\n",
    "model_b.fit(X_train, y_train, verbose=2, epochs=50,validation_split=0.3  )\n",
    "y_hat_b = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "00aca7b6-a0b1-41e8-8fd4-1970c7fb74dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_error:-  1415.2624510832559\n"
     ]
    }
   ],
   "source": [
    "print('mean_squared_error:- ', mean_squared_error(y_test,y_hat_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "972cb55b-4c88-47a6-b7ec-adfaa7b068ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iteration - ', 1, 'mean_squared_error - ', 325.65458559297184)\n",
      "('Iteration - ', 2, 'mean_squared_error - ', 198.0106742827575)\n",
      "('Iteration - ', 3, 'mean_squared_error - ', 153.09433227104816)\n",
      "('Iteration - ', 4, 'mean_squared_error - ', 97.99171460355191)\n",
      "('Iteration - ', 5, 'mean_squared_error - ', 116.87218415129556)\n",
      "('Iteration - ', 6, 'mean_squared_error - ', 102.35585315718768)\n",
      "('Iteration - ', 7, 'mean_squared_error - ', 74.64199359772978)\n",
      "('Iteration - ', 8, 'mean_squared_error - ', 66.31049069201764)\n",
      "('Iteration - ', 9, 'mean_squared_error - ', 64.50691916814853)\n",
      "('Iteration - ', 10, 'mean_squared_error - ', 54.48897217275233)\n",
      "('Iteration - ', 11, 'mean_squared_error - ', 50.94029181067833)\n",
      "('Iteration - ', 12, 'mean_squared_error - ', 43.69087048112023)\n",
      "('Iteration - ', 13, 'mean_squared_error - ', 54.95267554237501)\n",
      "('Iteration - ', 14, 'mean_squared_error - ', 49.47252776496317)\n",
      "('Iteration - ', 15, 'mean_squared_error - ', 35.42743143321175)\n",
      "('Iteration - ', 16, 'mean_squared_error - ', 46.394181802455996)\n",
      "('Iteration - ', 17, 'mean_squared_error - ', 35.115549374753975)\n",
      "('Iteration - ', 18, 'mean_squared_error - ', 41.41476631575823)\n",
      "('Iteration - ', 19, 'mean_squared_error - ', 29.21155209711555)\n",
      "('Iteration - ', 20, 'mean_squared_error - ', 38.619616150454384)\n",
      "('Iteration - ', 21, 'mean_squared_error - ', 39.25931241650075)\n",
      "('Iteration - ', 22, 'mean_squared_error - ', 43.689319557196676)\n",
      "('Iteration - ', 23, 'mean_squared_error - ', 41.556721762163235)\n",
      "('Iteration - ', 24, 'mean_squared_error - ', 36.6834429601265)\n",
      "('Iteration - ', 25, 'mean_squared_error - ', 36.64848882755711)\n",
      "('Iteration - ', 26, 'mean_squared_error - ', 32.85802091501179)\n",
      "('Iteration - ', 27, 'mean_squared_error - ', 34.15629869838836)\n",
      "('Iteration - ', 28, 'mean_squared_error - ', 34.58773089509562)\n",
      "('Iteration - ', 29, 'mean_squared_error - ', 34.73804348884517)\n",
      "('Iteration - ', 30, 'mean_squared_error - ', 32.690356726525636)\n",
      "('Iteration - ', 31, 'mean_squared_error - ', 35.72422187307032)\n",
      "('Iteration - ', 32, 'mean_squared_error - ', 37.51633542370364)\n",
      "('Iteration - ', 33, 'mean_squared_error - ', 33.65041752711661)\n",
      "('Iteration - ', 34, 'mean_squared_error - ', 35.53952705810392)\n",
      "('Iteration - ', 35, 'mean_squared_error - ', 31.397712128054696)\n",
      "('Iteration - ', 36, 'mean_squared_error - ', 28.201881910357475)\n",
      "('Iteration - ', 37, 'mean_squared_error - ', 31.82795732267553)\n",
      "('Iteration - ', 38, 'mean_squared_error - ', 35.03338233947985)\n",
      "('Iteration - ', 39, 'mean_squared_error - ', 27.622273997459175)\n",
      "('Iteration - ', 40, 'mean_squared_error - ', 33.675101071737544)\n",
      "('Iteration - ', 41, 'mean_squared_error - ', 25.992181450292016)\n",
      "('Iteration - ', 42, 'mean_squared_error - ', 30.592941292508232)\n",
      "('Iteration - ', 43, 'mean_squared_error - ', 35.83812974135334)\n",
      "('Iteration - ', 44, 'mean_squared_error - ', 33.97192507730583)\n",
      "('Iteration - ', 45, 'mean_squared_error - ', 31.941528747437854)\n",
      "('Iteration - ', 46, 'mean_squared_error - ', 33.944531904278506)\n",
      "('Iteration - ', 47, 'mean_squared_error - ', 27.86202967734111)\n",
      "('Iteration - ', 48, 'mean_squared_error - ', 34.418506202379696)\n",
      "('Iteration - ', 49, 'mean_squared_error - ', 27.653459262188058)\n",
      "('Iteration - ', 50, 'mean_squared_error - ', 30.17230272200048)\n"
     ]
    }
   ],
   "source": [
    "model_b_2 = regression_model()\n",
    "lst_mse_2 = []\n",
    "for i in range(1,51):\n",
    "    mse = get_mse(model_a, predictor_norm, 50)\n",
    "    msg = ('Iteration - ', i, 'mean_squared_error - ', mse)\n",
    "    print(msg)\n",
    "    lst_mse_2.append(mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "783899d4-2a5c-4254-a85f-031d5378332d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 53.77\n",
      "standard deviation: 50.61\n"
     ]
    }
   ],
   "source": [
    "mse_B =np.mean(lst_mse_2)\n",
    "std_B = np.std((lst_mse_2))\n",
    "\n",
    "print(\"Mean: %.2f\" % np.mean(lst_mse_2))\n",
    "print(\"standard deviation: %.2f\" % np.std((lst_mse_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "718f31ac-6523-4fbd-aa92-10e6ce21c0a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 504 samples, validate on 217 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 1578.5334 - val_loss: 1384.4573\n",
      "Epoch 2/100\n",
      " - 0s - loss: 1568.3853 - val_loss: 1375.4172\n",
      "Epoch 3/100\n",
      " - 0s - loss: 1557.7617 - val_loss: 1366.1791\n",
      "Epoch 4/100\n",
      " - 0s - loss: 1546.9349 - val_loss: 1356.3785\n",
      "Epoch 5/100\n",
      " - 0s - loss: 1535.4469 - val_loss: 1346.1171\n",
      "Epoch 6/100\n",
      " - 0s - loss: 1523.2332 - val_loss: 1335.4763\n",
      "Epoch 7/100\n",
      " - 0s - loss: 1510.6347 - val_loss: 1324.2350\n",
      "Epoch 8/100\n",
      " - 0s - loss: 1497.1931 - val_loss: 1312.4935\n",
      "Epoch 9/100\n",
      " - 0s - loss: 1483.0402 - val_loss: 1300.1001\n",
      "Epoch 10/100\n",
      " - 0s - loss: 1468.1938 - val_loss: 1287.1424\n",
      "Epoch 11/100\n",
      " - 0s - loss: 1452.6953 - val_loss: 1273.5648\n",
      "Epoch 12/100\n",
      " - 0s - loss: 1436.2599 - val_loss: 1259.5525\n",
      "Epoch 13/100\n",
      " - 0s - loss: 1419.3740 - val_loss: 1244.7583\n",
      "Epoch 14/100\n",
      " - 0s - loss: 1401.3682 - val_loss: 1229.7513\n",
      "Epoch 15/100\n",
      " - 0s - loss: 1383.2472 - val_loss: 1213.8328\n",
      "Epoch 16/100\n",
      " - 0s - loss: 1364.1267 - val_loss: 1197.4242\n",
      "Epoch 17/100\n",
      " - 0s - loss: 1344.3305 - val_loss: 1180.4866\n",
      "Epoch 18/100\n",
      " - 0s - loss: 1323.7076 - val_loss: 1163.2142\n",
      "Epoch 19/100\n",
      " - 0s - loss: 1303.1054 - val_loss: 1145.0478\n",
      "Epoch 20/100\n",
      " - 0s - loss: 1281.2857 - val_loss: 1126.6482\n",
      "Epoch 21/100\n",
      " - 0s - loss: 1258.7725 - val_loss: 1107.9058\n",
      "Epoch 22/100\n",
      " - 0s - loss: 1236.0022 - val_loss: 1088.4109\n",
      "Epoch 23/100\n",
      " - 0s - loss: 1212.8799 - val_loss: 1068.2327\n",
      "Epoch 24/100\n",
      " - 0s - loss: 1188.6695 - val_loss: 1048.0400\n",
      "Epoch 25/100\n",
      " - 0s - loss: 1164.0160 - val_loss: 1027.8718\n",
      "Epoch 26/100\n",
      " - 0s - loss: 1139.7355 - val_loss: 1006.8308\n",
      "Epoch 27/100\n",
      " - 0s - loss: 1114.3871 - val_loss: 985.4987\n",
      "Epoch 28/100\n",
      " - 0s - loss: 1088.7566 - val_loss: 964.1623\n",
      "Epoch 29/100\n",
      " - 0s - loss: 1063.2414 - val_loss: 942.2522\n",
      "Epoch 30/100\n",
      " - 0s - loss: 1037.1100 - val_loss: 920.2120\n",
      "Epoch 31/100\n",
      " - 0s - loss: 1010.5150 - val_loss: 898.2082\n",
      "Epoch 32/100\n",
      " - 0s - loss: 984.1625 - val_loss: 876.0156\n",
      "Epoch 33/100\n",
      " - 0s - loss: 957.8208 - val_loss: 853.5460\n",
      "Epoch 34/100\n",
      " - 0s - loss: 931.5090 - val_loss: 830.7752\n",
      "Epoch 35/100\n",
      " - 0s - loss: 904.7710 - val_loss: 808.2412\n",
      "Epoch 36/100\n",
      " - 0s - loss: 877.6828 - val_loss: 786.4820\n",
      "Epoch 37/100\n",
      " - 0s - loss: 851.6915 - val_loss: 764.2368\n",
      "Epoch 38/100\n",
      " - 0s - loss: 825.5759 - val_loss: 741.9567\n",
      "Epoch 39/100\n",
      " - 0s - loss: 799.6321 - val_loss: 719.9065\n",
      "Epoch 40/100\n",
      " - 0s - loss: 773.9016 - val_loss: 697.9163\n",
      "Epoch 41/100\n",
      " - 0s - loss: 748.4312 - val_loss: 676.4786\n",
      "Epoch 42/100\n",
      " - 0s - loss: 723.5597 - val_loss: 655.4237\n",
      "Epoch 43/100\n",
      " - 0s - loss: 699.1279 - val_loss: 634.9482\n",
      "Epoch 44/100\n",
      " - 0s - loss: 675.5502 - val_loss: 614.8138\n",
      "Epoch 45/100\n",
      " - 0s - loss: 652.2948 - val_loss: 594.9777\n",
      "Epoch 46/100\n",
      " - 0s - loss: 629.7954 - val_loss: 575.6212\n",
      "Epoch 47/100\n",
      " - 0s - loss: 607.7940 - val_loss: 556.7262\n",
      "Epoch 48/100\n",
      " - 0s - loss: 586.1281 - val_loss: 538.4553\n",
      "Epoch 49/100\n",
      " - 0s - loss: 565.5029 - val_loss: 520.4834\n",
      "Epoch 50/100\n",
      " - 0s - loss: 545.5689 - val_loss: 502.9263\n",
      "Epoch 51/100\n",
      " - 0s - loss: 525.9709 - val_loss: 486.4362\n",
      "Epoch 52/100\n",
      " - 0s - loss: 507.8563 - val_loss: 470.2060\n",
      "Epoch 53/100\n",
      " - 0s - loss: 489.6907 - val_loss: 454.7698\n",
      "Epoch 54/100\n",
      " - 0s - loss: 472.5492 - val_loss: 439.9091\n",
      "Epoch 55/100\n",
      " - 0s - loss: 456.3302 - val_loss: 425.3487\n",
      "Epoch 56/100\n",
      " - 0s - loss: 440.3918 - val_loss: 411.7230\n",
      "Epoch 57/100\n",
      " - 0s - loss: 425.6836 - val_loss: 398.2643\n",
      "Epoch 58/100\n",
      " - 0s - loss: 411.6259 - val_loss: 385.2989\n",
      "Epoch 59/100\n",
      " - 0s - loss: 397.7455 - val_loss: 373.3088\n",
      "Epoch 60/100\n",
      " - 0s - loss: 384.9800 - val_loss: 361.8484\n",
      "Epoch 61/100\n",
      " - 0s - loss: 372.7861 - val_loss: 350.8423\n",
      "Epoch 62/100\n",
      " - 0s - loss: 361.3802 - val_loss: 340.3024\n",
      "Epoch 63/100\n",
      " - 0s - loss: 350.3973 - val_loss: 330.2745\n",
      "Epoch 64/100\n",
      " - 0s - loss: 340.3657 - val_loss: 320.5773\n",
      "Epoch 65/100\n",
      " - 0s - loss: 330.0785 - val_loss: 311.8041\n",
      "Epoch 66/100\n",
      " - 0s - loss: 321.1752 - val_loss: 303.1546\n",
      "Epoch 67/100\n",
      " - 0s - loss: 312.5686 - val_loss: 294.8912\n",
      "Epoch 68/100\n",
      " - 0s - loss: 304.3135 - val_loss: 287.0925\n",
      "Epoch 69/100\n",
      " - 0s - loss: 296.4438 - val_loss: 279.9516\n",
      "Epoch 70/100\n",
      " - 0s - loss: 289.4258 - val_loss: 272.9537\n",
      "Epoch 71/100\n",
      " - 0s - loss: 282.4220 - val_loss: 266.5440\n",
      "Epoch 72/100\n",
      " - 0s - loss: 276.1884 - val_loss: 260.1651\n",
      "Epoch 73/100\n",
      " - 0s - loss: 270.0070 - val_loss: 254.4155\n",
      "Epoch 74/100\n",
      " - 0s - loss: 264.5033 - val_loss: 248.9106\n",
      "Epoch 75/100\n",
      " - 0s - loss: 258.9856 - val_loss: 243.7541\n",
      "Epoch 76/100\n",
      " - 0s - loss: 254.1664 - val_loss: 238.7144\n",
      "Epoch 77/100\n",
      " - 0s - loss: 249.3324 - val_loss: 234.0525\n",
      "Epoch 78/100\n",
      " - 0s - loss: 244.7981 - val_loss: 229.7337\n",
      "Epoch 79/100\n",
      " - 0s - loss: 240.7558 - val_loss: 225.5907\n",
      "Epoch 80/100\n",
      " - 0s - loss: 236.8390 - val_loss: 221.5731\n",
      "Epoch 81/100\n",
      " - 0s - loss: 233.1022 - val_loss: 217.6743\n",
      "Epoch 82/100\n",
      " - 0s - loss: 229.4460 - val_loss: 214.2218\n",
      "Epoch 83/100\n",
      " - 0s - loss: 226.1072 - val_loss: 210.9982\n",
      "Epoch 84/100\n",
      " - 0s - loss: 223.0689 - val_loss: 207.7445\n",
      "Epoch 85/100\n",
      " - 0s - loss: 219.9118 - val_loss: 204.7821\n",
      "Epoch 86/100\n",
      " - 0s - loss: 217.0058 - val_loss: 202.0830\n",
      "Epoch 87/100\n",
      " - 0s - loss: 214.3599 - val_loss: 199.3441\n",
      "Epoch 88/100\n",
      " - 0s - loss: 211.8075 - val_loss: 196.7110\n",
      "Epoch 89/100\n",
      " - 0s - loss: 209.2794 - val_loss: 194.2312\n",
      "Epoch 90/100\n",
      " - 0s - loss: 206.8060 - val_loss: 191.9184\n",
      "Epoch 91/100\n",
      " - 0s - loss: 204.5435 - val_loss: 189.7392\n",
      "Epoch 92/100\n",
      " - 0s - loss: 202.3290 - val_loss: 187.6809\n",
      "Epoch 93/100\n",
      " - 0s - loss: 200.2956 - val_loss: 185.5926\n",
      "Epoch 94/100\n",
      " - 0s - loss: 198.2756 - val_loss: 183.6508\n",
      "Epoch 95/100\n",
      " - 0s - loss: 196.3824 - val_loss: 181.9472\n",
      "Epoch 96/100\n",
      " - 0s - loss: 194.4902 - val_loss: 180.1614\n",
      "Epoch 97/100\n",
      " - 0s - loss: 192.6425 - val_loss: 178.4641\n",
      "Epoch 98/100\n",
      " - 0s - loss: 190.8856 - val_loss: 176.7917\n",
      "Epoch 99/100\n",
      " - 0s - loss: 189.2753 - val_loss: 175.3138\n",
      "Epoch 100/100\n",
      " - 0s - loss: 187.6223 - val_loss: 173.8380\n"
     ]
    }
   ],
   "source": [
    "#C. Increate the number of epochs (5 marks)\n",
    "#Repeat Part B but use 100 epochs this time for training.\n",
    "#How does the mean of the mean squared errors compare to that from Step B?\n",
    "model_c = regression_model()\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictor_norm, y, test_size=0.3)\n",
    "model_c.fit(X_train,y_train, verbose=2, validation_split=0.3, epochs=100)\n",
    "y_hat_c= model_c.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "312e5ea0-86ee-4870-8768-b9b1b0dddc1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_error:-  202.4320224946448\n"
     ]
    }
   ],
   "source": [
    "print('mean_squared_error:- ', mean_squared_error(y_test,y_hat_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "74ddaaf9-4aae-4ecf-ad97-1a9687fd4889",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iteration - ', 1, 'mean_squared_error - ', 183.41583888625695)\n",
      "('Iteration - ', 2, 'mean_squared_error - ', 140.57976252253272)\n",
      "('Iteration - ', 3, 'mean_squared_error - ', 84.37630025546176)\n",
      "('Iteration - ', 4, 'mean_squared_error - ', 64.40575329951018)\n",
      "('Iteration - ', 5, 'mean_squared_error - ', 50.41232060545421)\n",
      "('Iteration - ', 6, 'mean_squared_error - ', 42.91068695585371)\n",
      "('Iteration - ', 7, 'mean_squared_error - ', 41.008039096080616)\n",
      "('Iteration - ', 8, 'mean_squared_error - ', 41.1594957029661)\n",
      "('Iteration - ', 9, 'mean_squared_error - ', 37.49653017345371)\n",
      "('Iteration - ', 10, 'mean_squared_error - ', 41.96099575472533)\n",
      "('Iteration - ', 11, 'mean_squared_error - ', 36.43627926964177)\n",
      "('Iteration - ', 12, 'mean_squared_error - ', 39.21870150841907)\n",
      "('Iteration - ', 13, 'mean_squared_error - ', 36.77096595847391)\n",
      "('Iteration - ', 14, 'mean_squared_error - ', 43.43247649567989)\n",
      "('Iteration - ', 15, 'mean_squared_error - ', 35.5272730194927)\n",
      "('Iteration - ', 16, 'mean_squared_error - ', 33.25160866285535)\n",
      "('Iteration - ', 17, 'mean_squared_error - ', 34.98882588656652)\n",
      "('Iteration - ', 18, 'mean_squared_error - ', 35.08646933848026)\n",
      "('Iteration - ', 19, 'mean_squared_error - ', 37.956331023008396)\n",
      "('Iteration - ', 20, 'mean_squared_error - ', 32.72545310707005)\n",
      "('Iteration - ', 21, 'mean_squared_error - ', 33.69700353728336)\n",
      "('Iteration - ', 22, 'mean_squared_error - ', 39.76462086218966)\n",
      "('Iteration - ', 23, 'mean_squared_error - ', 33.67557631901123)\n",
      "('Iteration - ', 24, 'mean_squared_error - ', 32.035883760170655)\n",
      "('Iteration - ', 25, 'mean_squared_error - ', 38.638457045868165)\n",
      "('Iteration - ', 26, 'mean_squared_error - ', 35.578095908197874)\n",
      "('Iteration - ', 27, 'mean_squared_error - ', 32.00482019190893)\n",
      "('Iteration - ', 28, 'mean_squared_error - ', 34.771530804185105)\n",
      "('Iteration - ', 29, 'mean_squared_error - ', 34.7795092333541)\n",
      "('Iteration - ', 30, 'mean_squared_error - ', 34.75025179693091)\n",
      "('Iteration - ', 31, 'mean_squared_error - ', 39.94550572047409)\n",
      "('Iteration - ', 32, 'mean_squared_error - ', 31.02289686755383)\n",
      "('Iteration - ', 33, 'mean_squared_error - ', 33.58571885246861)\n",
      "('Iteration - ', 34, 'mean_squared_error - ', 35.256545832834426)\n",
      "('Iteration - ', 35, 'mean_squared_error - ', 32.50059709525656)\n",
      "('Iteration - ', 36, 'mean_squared_error - ', 33.206124933958726)\n",
      "('Iteration - ', 37, 'mean_squared_error - ', 34.52954158736834)\n",
      "('Iteration - ', 38, 'mean_squared_error - ', 34.17984764987474)\n",
      "('Iteration - ', 39, 'mean_squared_error - ', 33.49219287328603)\n",
      "('Iteration - ', 40, 'mean_squared_error - ', 31.75847139806769)\n",
      "('Iteration - ', 41, 'mean_squared_error - ', 32.0354457743492)\n",
      "('Iteration - ', 42, 'mean_squared_error - ', 34.02246561391774)\n",
      "('Iteration - ', 43, 'mean_squared_error - ', 32.14126930810936)\n",
      "('Iteration - ', 44, 'mean_squared_error - ', 32.41921921518386)\n",
      "('Iteration - ', 45, 'mean_squared_error - ', 31.370865299699435)\n",
      "('Iteration - ', 46, 'mean_squared_error - ', 38.97332396778067)\n",
      "('Iteration - ', 47, 'mean_squared_error - ', 34.12310071974644)\n",
      "('Iteration - ', 48, 'mean_squared_error - ', 29.421142697325482)\n",
      "('Iteration - ', 49, 'mean_squared_error - ', 34.02611669407242)\n",
      "('Iteration - ', 50, 'mean_squared_error - ', 30.003889975442597)\n"
     ]
    }
   ],
   "source": [
    "model_c_2 = regression_model()\n",
    "lst_mse_3=[]\n",
    "for i in range(1,51):\n",
    "    mse = get_mse(model_c_2,predictor_norm,100 )\n",
    "    msg = ('Iteration - ', i, 'mean_squared_error - ', mse)\n",
    "    print(msg)\n",
    "    lst_mse_3.append(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c5c54a99-a476-4f53-b01a-464d4e9f9284",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 42.22\n",
      "standard deviation: 26.32\n"
     ]
    }
   ],
   "source": [
    "mse_C =np.mean(lst_mse_3)\n",
    "std_C = np.std((lst_mse_3))\n",
    "print(\"Mean: %.2f\" % np.mean(lst_mse_3))\n",
    "print(\"standard deviation: %.2f\" % np.std((lst_mse_3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d4ff7900-7e32-4ff8-86bc-19a7acde9dbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#D. Increase the number of hidden layers (5 marks)\n",
    "#Repeat part B but use a neural network with the following instead:\n",
    "#- Three hidden layers, each of 10 nodes and ReLU activation function.\n",
    "#How does the mean of the mean squared errors compare to that from Step B?\n",
    "def regrssion_model_2():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu',input_shape=(n_cols,)))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fb7323a5-75f7-48ec-b1ca-2516d5b0eda5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 504 samples, validate on 217 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 1559.2467 - acc: 0.0000e+00 - val_loss: 1501.4056 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      " - 0s - loss: 1542.8826 - acc: 0.0000e+00 - val_loss: 1483.1755 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      " - 0s - loss: 1523.0356 - acc: 0.0000e+00 - val_loss: 1461.0292 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      " - 0s - loss: 1497.8834 - acc: 0.0000e+00 - val_loss: 1432.3481 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      " - 0s - loss: 1465.0334 - acc: 0.0000e+00 - val_loss: 1394.5547 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      " - 0s - loss: 1421.6398 - acc: 0.0000e+00 - val_loss: 1346.7234 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      " - 0s - loss: 1366.2089 - acc: 0.0000e+00 - val_loss: 1285.8256 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      " - 0s - loss: 1296.7755 - acc: 0.0000e+00 - val_loss: 1208.2529 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      " - 0s - loss: 1209.2826 - acc: 0.0000e+00 - val_loss: 1111.8017 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      " - 0s - loss: 1101.8109 - acc: 0.0000e+00 - val_loss: 997.6232 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      " - 0s - loss: 974.3086 - acc: 0.0000e+00 - val_loss: 866.7526 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      " - 0s - loss: 834.3018 - acc: 0.0000e+00 - val_loss: 724.0964 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      " - 0s - loss: 687.1072 - acc: 0.0000e+00 - val_loss: 581.0776 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      " - 0s - loss: 541.3771 - acc: 0.0000e+00 - val_loss: 459.2610 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      " - 0s - loss: 427.4485 - acc: 0.0000e+00 - val_loss: 365.6103 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      " - 0s - loss: 343.3324 - acc: 0.0000e+00 - val_loss: 307.0491 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      " - 0s - loss: 293.3853 - acc: 0.0000e+00 - val_loss: 274.5535 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      " - 0s - loss: 263.6073 - acc: 0.0000e+00 - val_loss: 257.1112 - val_acc: 0.0046\n",
      "Epoch 19/100\n",
      " - 0s - loss: 247.2591 - acc: 0.0000e+00 - val_loss: 245.2966 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      " - 0s - loss: 233.1065 - acc: 0.0000e+00 - val_loss: 235.6011 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      " - 0s - loss: 222.3100 - acc: 0.0000e+00 - val_loss: 227.3992 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      " - 0s - loss: 213.5461 - acc: 0.0000e+00 - val_loss: 220.4286 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      " - 0s - loss: 205.7965 - acc: 0.0000e+00 - val_loss: 214.8169 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      " - 0s - loss: 199.3595 - acc: 0.0000e+00 - val_loss: 208.7792 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      " - 0s - loss: 192.9288 - acc: 0.0000e+00 - val_loss: 204.0411 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      " - 0s - loss: 188.1603 - acc: 0.0000e+00 - val_loss: 198.6465 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      " - 0s - loss: 183.0618 - acc: 0.0000e+00 - val_loss: 194.7902 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      " - 0s - loss: 179.2030 - acc: 0.0000e+00 - val_loss: 190.7699 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      " - 0s - loss: 175.6627 - acc: 0.0000e+00 - val_loss: 187.3907 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      " - 0s - loss: 172.2386 - acc: 0.0000e+00 - val_loss: 183.6579 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      " - 0s - loss: 169.1746 - acc: 0.0000e+00 - val_loss: 180.4534 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      " - 0s - loss: 166.1189 - acc: 0.0000e+00 - val_loss: 177.5404 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      " - 0s - loss: 163.5025 - acc: 0.0000e+00 - val_loss: 174.3396 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      " - 0s - loss: 161.3515 - acc: 0.0000e+00 - val_loss: 171.7085 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      " - 0s - loss: 158.7580 - acc: 0.0000e+00 - val_loss: 169.4376 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      " - 0s - loss: 156.2747 - acc: 0.0000e+00 - val_loss: 167.2759 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      " - 0s - loss: 154.2685 - acc: 0.0000e+00 - val_loss: 165.0889 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      " - 0s - loss: 152.6824 - acc: 0.0000e+00 - val_loss: 162.8249 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      " - 0s - loss: 150.5128 - acc: 0.0000e+00 - val_loss: 160.8637 - val_acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      " - 0s - loss: 148.7706 - acc: 0.0000e+00 - val_loss: 158.9321 - val_acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      " - 0s - loss: 147.1723 - acc: 0.0000e+00 - val_loss: 157.2190 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      " - 0s - loss: 145.9377 - acc: 0.0000e+00 - val_loss: 155.6382 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      " - 0s - loss: 144.6031 - acc: 0.0000e+00 - val_loss: 154.2287 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      " - 0s - loss: 143.2249 - acc: 0.0000e+00 - val_loss: 152.5944 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      " - 0s - loss: 141.9397 - acc: 0.0000e+00 - val_loss: 151.7254 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      " - 0s - loss: 140.3912 - acc: 0.0000e+00 - val_loss: 150.0434 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      " - 0s - loss: 138.9723 - acc: 0.0000e+00 - val_loss: 148.4130 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      " - 0s - loss: 137.7796 - acc: 0.0000e+00 - val_loss: 147.3372 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      " - 0s - loss: 136.7911 - acc: 0.0000e+00 - val_loss: 146.2453 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      " - 0s - loss: 135.6876 - acc: 0.0000e+00 - val_loss: 144.9982 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      " - 0s - loss: 134.5680 - acc: 0.0000e+00 - val_loss: 144.0458 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      " - 0s - loss: 133.5563 - acc: 0.0000e+00 - val_loss: 143.1557 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      " - 0s - loss: 132.6912 - acc: 0.0000e+00 - val_loss: 142.3718 - val_acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      " - 0s - loss: 132.2165 - acc: 0.0000e+00 - val_loss: 141.3611 - val_acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      " - 0s - loss: 130.9891 - acc: 0.0000e+00 - val_loss: 140.7724 - val_acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      " - 0s - loss: 130.2507 - acc: 0.0000e+00 - val_loss: 139.9082 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      " - 0s - loss: 129.5678 - acc: 0.0000e+00 - val_loss: 138.7963 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      " - 0s - loss: 128.4085 - acc: 0.0000e+00 - val_loss: 138.2040 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      " - 0s - loss: 127.7955 - acc: 0.0000e+00 - val_loss: 137.3483 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      " - 0s - loss: 126.9414 - acc: 0.0000e+00 - val_loss: 136.5757 - val_acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      " - 0s - loss: 126.2895 - acc: 0.0000e+00 - val_loss: 135.5315 - val_acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      " - 0s - loss: 125.7265 - acc: 0.0000e+00 - val_loss: 134.9831 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      " - 0s - loss: 124.6919 - acc: 0.0000e+00 - val_loss: 134.3676 - val_acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      " - 0s - loss: 124.2432 - acc: 0.0000e+00 - val_loss: 133.4651 - val_acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      " - 0s - loss: 123.6373 - acc: 0.0000e+00 - val_loss: 132.8461 - val_acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      " - 0s - loss: 122.8697 - acc: 0.0000e+00 - val_loss: 132.2754 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      " - 0s - loss: 122.1186 - acc: 0.0000e+00 - val_loss: 131.4763 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      " - 0s - loss: 121.7568 - acc: 0.0000e+00 - val_loss: 130.9919 - val_acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      " - 0s - loss: 121.2733 - acc: 0.0000e+00 - val_loss: 130.1804 - val_acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      " - 0s - loss: 120.1318 - acc: 0.0000e+00 - val_loss: 129.5660 - val_acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      " - 0s - loss: 119.6428 - acc: 0.0000e+00 - val_loss: 129.0878 - val_acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      " - 0s - loss: 119.2346 - acc: 0.0000e+00 - val_loss: 128.4327 - val_acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      " - 0s - loss: 118.6933 - acc: 0.0000e+00 - val_loss: 127.9807 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      " - 0s - loss: 118.2216 - acc: 0.0000e+00 - val_loss: 127.2335 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      " - 0s - loss: 117.3527 - acc: 0.0000e+00 - val_loss: 126.5443 - val_acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      " - 0s - loss: 116.8091 - acc: 0.0000e+00 - val_loss: 125.8839 - val_acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      " - 0s - loss: 116.4444 - acc: 0.0000e+00 - val_loss: 125.4662 - val_acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      " - 0s - loss: 115.9533 - acc: 0.0000e+00 - val_loss: 124.9975 - val_acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      " - 0s - loss: 115.2912 - acc: 0.0000e+00 - val_loss: 124.3512 - val_acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      " - 0s - loss: 114.9347 - acc: 0.0000e+00 - val_loss: 123.8210 - val_acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      " - 0s - loss: 114.4388 - acc: 0.0000e+00 - val_loss: 123.1778 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      " - 0s - loss: 113.9917 - acc: 0.0000e+00 - val_loss: 123.0049 - val_acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      " - 0s - loss: 113.3987 - acc: 0.0000e+00 - val_loss: 122.2952 - val_acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      " - 0s - loss: 112.8186 - acc: 0.0000e+00 - val_loss: 121.8116 - val_acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      " - 0s - loss: 112.5673 - acc: 0.0000e+00 - val_loss: 121.4849 - val_acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      " - 0s - loss: 112.1235 - acc: 0.0000e+00 - val_loss: 121.2206 - val_acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      " - 0s - loss: 112.4341 - acc: 0.0000e+00 - val_loss: 120.5444 - val_acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      " - 0s - loss: 111.5900 - acc: 0.0000e+00 - val_loss: 120.2445 - val_acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      " - 0s - loss: 110.5956 - acc: 0.0000e+00 - val_loss: 119.7247 - val_acc: 0.0046\n",
      "Epoch 90/100\n",
      " - 0s - loss: 110.2515 - acc: 0.0000e+00 - val_loss: 119.0186 - val_acc: 0.0046\n",
      "Epoch 91/100\n",
      " - 0s - loss: 109.6235 - acc: 0.0000e+00 - val_loss: 118.7753 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      " - 0s - loss: 109.2176 - acc: 0.0000e+00 - val_loss: 118.3597 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      " - 0s - loss: 108.8998 - acc: 0.0000e+00 - val_loss: 117.9261 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      " - 0s - loss: 108.2215 - acc: 0.0000e+00 - val_loss: 117.5733 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      " - 0s - loss: 107.7867 - acc: 0.0000e+00 - val_loss: 116.8681 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      " - 0s - loss: 107.5151 - acc: 0.0000e+00 - val_loss: 116.3779 - val_acc: 0.0046\n",
      "Epoch 97/100\n",
      " - 0s - loss: 106.7757 - acc: 0.0000e+00 - val_loss: 115.8251 - val_acc: 0.0046\n",
      "Epoch 98/100\n",
      " - 0s - loss: 106.4251 - acc: 0.0000e+00 - val_loss: 115.4014 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      " - 0s - loss: 106.3795 - acc: 0.0000e+00 - val_loss: 114.9082 - val_acc: 0.0046\n",
      "Epoch 100/100\n",
      " - 0s - loss: 105.3790 - acc: 0.0000e+00 - val_loss: 114.2695 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "model_d = regrssion_model_2()\n",
    "X_train,X_test,y_train,y_test = train_test_split(predictor_norm,y, test_size=0.3)\n",
    "model_d.fit(X_train,y_train, epochs=100, verbose=2, validation_split=0.3)\n",
    "y_hat_d = model_d.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8ded9f53-037e-4e27-ba23-b6b00fe90716",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120.1814893303102\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(y_test, y_hat_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "62e924b5-9f7d-4624-bc22-186cfd302b44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iteration - ', 1, 'mean_squared_error - ', 79.40776751124987)\n",
      "('Iteration - ', 2, 'mean_squared_error - ', 60.414590608881085)\n",
      "('Iteration - ', 3, 'mean_squared_error - ', 53.22511553959699)\n",
      "('Iteration - ', 4, 'mean_squared_error - ', 38.3891794621707)\n",
      "('Iteration - ', 5, 'mean_squared_error - ', 38.47784865122406)\n",
      "('Iteration - ', 6, 'mean_squared_error - ', 33.71067201234072)\n",
      "('Iteration - ', 7, 'mean_squared_error - ', 30.972871728628142)\n",
      "('Iteration - ', 8, 'mean_squared_error - ', 30.40171887142203)\n",
      "('Iteration - ', 9, 'mean_squared_error - ', 36.88975105989303)\n",
      "('Iteration - ', 10, 'mean_squared_error - ', 33.19862216084634)\n",
      "('Iteration - ', 11, 'mean_squared_error - ', 33.14141409304714)\n",
      "('Iteration - ', 12, 'mean_squared_error - ', 35.4624613487557)\n",
      "('Iteration - ', 13, 'mean_squared_error - ', 31.138435631253785)\n",
      "('Iteration - ', 14, 'mean_squared_error - ', 28.445222702903962)\n",
      "('Iteration - ', 15, 'mean_squared_error - ', 30.088754925625388)\n",
      "('Iteration - ', 16, 'mean_squared_error - ', 27.972114471891633)\n",
      "('Iteration - ', 17, 'mean_squared_error - ', 27.92519078708109)\n",
      "('Iteration - ', 18, 'mean_squared_error - ', 26.046631660278578)\n",
      "('Iteration - ', 19, 'mean_squared_error - ', 27.549044562281036)\n",
      "('Iteration - ', 20, 'mean_squared_error - ', 35.55542187024811)\n",
      "('Iteration - ', 21, 'mean_squared_error - ', 28.05093905919152)\n",
      "('Iteration - ', 22, 'mean_squared_error - ', 26.91397035915604)\n",
      "('Iteration - ', 23, 'mean_squared_error - ', 26.83278431861133)\n",
      "('Iteration - ', 24, 'mean_squared_error - ', 26.744694145471954)\n",
      "('Iteration - ', 25, 'mean_squared_error - ', 23.495492395310936)\n",
      "('Iteration - ', 26, 'mean_squared_error - ', 27.009345185137253)\n",
      "('Iteration - ', 27, 'mean_squared_error - ', 20.132248565452787)\n",
      "('Iteration - ', 28, 'mean_squared_error - ', 27.353851226603698)\n",
      "('Iteration - ', 29, 'mean_squared_error - ', 26.49405866862407)\n",
      "('Iteration - ', 30, 'mean_squared_error - ', 26.233519326721613)\n",
      "('Iteration - ', 31, 'mean_squared_error - ', 22.60552955925221)\n",
      "('Iteration - ', 32, 'mean_squared_error - ', 27.770085674789982)\n",
      "('Iteration - ', 33, 'mean_squared_error - ', 25.205189581142218)\n",
      "('Iteration - ', 34, 'mean_squared_error - ', 24.525589131714714)\n",
      "('Iteration - ', 35, 'mean_squared_error - ', 22.756450904868032)\n",
      "('Iteration - ', 36, 'mean_squared_error - ', 29.324325871398514)\n",
      "('Iteration - ', 37, 'mean_squared_error - ', 20.716596048624897)\n",
      "('Iteration - ', 38, 'mean_squared_error - ', 18.757246324359357)\n",
      "('Iteration - ', 39, 'mean_squared_error - ', 24.010871705921133)\n",
      "('Iteration - ', 40, 'mean_squared_error - ', 23.934294829067067)\n",
      "('Iteration - ', 41, 'mean_squared_error - ', 20.152458561528313)\n",
      "('Iteration - ', 42, 'mean_squared_error - ', 21.206166186089334)\n",
      "('Iteration - ', 43, 'mean_squared_error - ', 23.041714354359645)\n",
      "('Iteration - ', 44, 'mean_squared_error - ', 20.49498148652337)\n",
      "('Iteration - ', 45, 'mean_squared_error - ', 21.452890535191525)\n",
      "('Iteration - ', 46, 'mean_squared_error - ', 23.914104353063802)\n",
      "('Iteration - ', 47, 'mean_squared_error - ', 25.716307889480667)\n",
      "('Iteration - ', 48, 'mean_squared_error - ', 25.17467883072636)\n",
      "('Iteration - ', 49, 'mean_squared_error - ', 17.574693100575907)\n",
      "('Iteration - ', 50, 'mean_squared_error - ', 22.349670084078067)\n"
     ]
    }
   ],
   "source": [
    "model_d_2 = regrssion_model_2()\n",
    "lst_mse_4=[]\n",
    "\n",
    "for i in range(1,51):\n",
    "    mse = get_mse(model_d_2,predictor_norm,100)\n",
    "    msg = ('Iteration - ', i, 'mean_squared_error - ', mse)\n",
    "    lst_mse_4.append(mse)\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1a33760d-9855-494f-857a-c9a6e2651eb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.167151558453114\n",
      "10.52104269586639\n"
     ]
    }
   ],
   "source": [
    "mse_D =np.mean(lst_mse_4)\n",
    "std_D = np.std((lst_mse_4))\n",
    "\n",
    "print(np.mean(lst_mse_4))\n",
    "print(np.std(lst_mse_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aa7f11b0-41b9-4b5e-8b2a-9f86b358e6d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[79.40776751124987,\n",
       " 60.414590608881085,\n",
       " 53.22511553959699,\n",
       " 38.3891794621707,\n",
       " 38.47784865122406,\n",
       " 33.71067201234072,\n",
       " 30.972871728628142,\n",
       " 30.40171887142203,\n",
       " 36.88975105989303,\n",
       " 33.19862216084634,\n",
       " 33.14141409304714,\n",
       " 35.4624613487557,\n",
       " 31.138435631253785,\n",
       " 28.445222702903962,\n",
       " 30.088754925625388]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_mse_4[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1d254c44-8aa3-417b-84fa-dc8f9efebdd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A - Mean: 97.28\n",
      "A - standard deviation: 139.22\n",
      "B - Mean: 53.77\n",
      "B - standard deviation: 50.61\n",
      "C - Mean: 42.22\n",
      "C - standard deviation: 26.32\n",
      "D - Mean: 29.17\n",
      "D - standard deviation: 10.52\n"
     ]
    }
   ],
   "source": [
    "print(\"A - Mean: %.2f\" % mse_A)\n",
    "print(\"A - standard deviation: %.2f\" % std_A)\n",
    "\n",
    "print(\"B - Mean: %.2f\" % mse_B)\n",
    "print(\"B - standard deviation: %.2f\" % std_B)\n",
    "\n",
    "print(\"C - Mean: %.2f\" % mse_C)\n",
    "print(\"C - standard deviation: %.2f\" % std_C)\n",
    "\n",
    "print(\"D - Mean: %.2f\" % mse_D)\n",
    "print(\"D - standard deviation: %.2f\" % std_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af32c8fc-c16f-47fe-80ee-ee78b0148ebb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
