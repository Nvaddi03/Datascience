{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec23789a",
   "metadata": {},
   "source": [
    "### Creating and registering tabular datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61de2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "blob_ds = ws.get_default_datastore()\n",
    "csv_paths = [(blob_ds, 'data/files/current_data.csv'),\n",
    "             (blob_ds, 'data/files/archive/*.csv')]\n",
    "tab_ds = Dataset.Tabular.from_delimited_files(path=csv_paths)\n",
    "tab_ds = tab_ds.register(workspace=ws, name='csv_table')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f07534",
   "metadata": {},
   "source": [
    "### Creating and registering file datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9d2b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "blob_ds = ws.get_default_datastore()\n",
    "file_ds = Dataset.File.from_files(path=(blob_ds, 'data/files/images/*.jpg'))\n",
    "file_ds = file_ds.register(workspace=ws, name='img_files')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f63ae3",
   "metadata": {},
   "source": [
    "### Retrieving a registered dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d92e6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace, Dataset\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "# Get a dataset from the workspace datasets collection\n",
    "ds1 = ws.datasets['csv_table']\n",
    "\n",
    "# Get a dataset by name from the datasets class\n",
    "ds2 = Dataset.get_by_name(ws, 'img_files')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c06a289",
   "metadata": {},
   "source": [
    "### Dataset versioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631f6f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = [(blob_ds, 'data/files/images/*.jpg'),\n",
    "             (blob_ds, 'data/files/images/*.png')]\n",
    "file_ds = Dataset.File.from_files(path=img_paths)\n",
    "file_ds = file_ds.register(workspace=ws, name='img_files', create_new_version=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d70d92",
   "metadata": {},
   "source": [
    "### Retrieving a specific dataset version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff462b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ds = Dataset.get_by_name(workspace=ws, name='img_files', version=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90065756",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74d284e5",
   "metadata": {},
   "source": [
    "### Use datasets\n",
    "\n",
    "Datasets are the primary way to pass data to experiments that train models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3155548d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Work with tabular datasets\n",
    "\n",
    "df = tab_ds.to_pandas_dataframe()\n",
    "# code to work with dataframe goes here, for example:\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58e4ea0",
   "metadata": {},
   "source": [
    "### use a script argument for a tabular dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063d7c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pass a tabular dataset to an experiment script\n",
    "#Use a script argument for a tabular dataset\n",
    "#ScriptRunConfig:\n",
    "\n",
    "env = Environment('my_env')\n",
    "packages = CondaDependencies.create(conda_packages=['pip'],\n",
    "                                    pip_packages=['azureml-defaults',\n",
    "                                                  'azureml-dataprep[pandas]'])\n",
    "env.python.conda_dependencies = packages\n",
    "\n",
    "script_config = ScriptRunConfig(source_directory='my_dir',\n",
    "                                script='script.py',\n",
    "                                arguments=['--ds', tab_ds],\n",
    "                                environment=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f37017d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script\n",
    "\n",
    "from azureml.core import Run, Dataset\n",
    "\n",
    "parser.add_argument('--ds', type=str, dest='dataset_id')\n",
    "args = parser.parse_args()\n",
    "\n",
    "run = Run.get_context()\n",
    "ws = run.experiment.workspace\n",
    "dataset = Dataset.get_by_id(ws, id=args.dataset_id)\n",
    "data = dataset.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552d59bd",
   "metadata": {},
   "source": [
    "### Use a named input for a tabular dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f927ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ScriptRunConfig:\n",
    "\n",
    "env = Environment('my_env')\n",
    "packages = CondaDependencies.create(conda_packages=['pip'],\n",
    "                                    pip_packages=['azureml-defaults',\n",
    "                                                  'azureml-dataprep[pandas]'])\n",
    "env.python.conda_dependencies = packages\n",
    "\n",
    "script_config = ScriptRunConfig(source_directory='my_dir',\n",
    "                                script='script.py',\n",
    "                                arguments=['--ds', tab_ds.as_named_input('my_dataset')],\n",
    "                                environment=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f18e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script\n",
    "\n",
    "from azureml.core import Run\n",
    "\n",
    "parser.add_argument('--ds', type=str, dest='ds_id')\n",
    "args = parser.parse_args()\n",
    "\n",
    "run = Run.get_context()\n",
    "dataset = run.input_datasets['my_dataset']\n",
    "data = dataset.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a265e840",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  return a list of the file paths encapsulated by the dataset\n",
    "\n",
    "for file_path in file_ds.to_path():\n",
    "    print(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b2f136",
   "metadata": {},
   "source": [
    "### Use a script argument for a file dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826c4055",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ScriptRunConfig:\n",
    "\n",
    "env = Environment('my_env')\n",
    "packages = CondaDependencies.create(conda_packages=['pip'],\n",
    "                                    pip_packages=['azureml-defaults',\n",
    "                                                  'azureml-dataprep[pandas]'])\n",
    "env.python.conda_dependencies = packages\n",
    "\n",
    "script_config = ScriptRunConfig(source_directory='my_dir',\n",
    "                                script='script.py',\n",
    "                                arguments=['--ds', file_ds.as_download()],\n",
    "                                environment=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6064896b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script\n",
    "from azureml.core import Run\n",
    "import glob\n",
    "\n",
    "parser.add_argument('--ds', type=str, dest='ds_ref')\n",
    "args = parser.parse_args()\n",
    "run = Run.get_context()\n",
    "\n",
    "imgs = glob.glob(args.ds_ref + \"/*.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89470fc",
   "metadata": {},
   "source": [
    "### Use a named input for a file dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f4aec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ScriptRunConfig:\n",
    "\n",
    "env = Environment('my_env')\n",
    "packages = CondaDependencies.create(conda_packages=['pip'],\n",
    "                                    pip_packages=['azureml-defaults',\n",
    "                                                  'azureml-dataprep[pandas]'])\n",
    "env.python.conda_dependencies = packages\n",
    "\n",
    "script_config = ScriptRunConfig(source_directory='my_dir',\n",
    "                                script='script.py',\n",
    "                                arguments=['--ds', file_ds.as_named_input('my_ds').as_download()],\n",
    "                                environment=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66155e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Run\n",
    "import glob\n",
    "\n",
    "parser.add_argument('--ds', type=str, dest='ds_ref')\n",
    "args = parser.parse_args()\n",
    "run = Run.get_context()\n",
    "\n",
    "dataset = run.input_datasets['my_ds']\n",
    "imgs= glob.glob(dataset + \"/*.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
